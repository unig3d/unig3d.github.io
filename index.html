<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="UniG3D: A Unified 3D Object Generation Dataset.">
    <meta name="author" content="Qinghong Sun">

    <title>UniG3D: A Unified 3D Object Generation Dataset</title>

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
        <link rel="icon" href="imgs/logo.png" type="image/x-ico">



</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <!-- <img src="img/oo3d_teaser.gif" style="width:30%; margin-right:0px; margin-top:0px;"> -->
    <h1 class="nerf_title_v2">UniG3D</h1>
    <h1 class="nerf_subheader_v2">A Unified 3D Object Generation Dataset</h1>
<!--     <h1 class="nerf_subheader_v2">CVPR 2023 (Award Candidate)</h1> -->
    <hr>
    <p class="authors">
      Authors
<!--       <a href=https://wutong16.github.io/ target="_blank"> Tong Wu</a><sup>1,2</sup>,
      <a href=> Jiarui Zhang</a><sup>1,3</sup>,
      <a href=https://fuxiao0719.github.io/ target="_blank"> Xiao Fu</a><sup>1</sup>,
      <a href=> Yuxin Wang</a><sup>1,4</sup>,
      <a href=https://jiawei-ren.github.io/ target="_blank"> Jiawei Ren</a><sup>5</sup>,
      <a href=https://scholar.google.com/citations?user=lSDISOcAAAAJ&hl=zh-CN target="_blank"> Liang Pan</a><sup>5</sup>,
        <br>
      <a href=https://wywu.github.io/ target="_blank"> Wayne Wu</a><sup>1</sup>,
      <a href=https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en target="_blank"> Lei Yang</a><sup>1,3</sup>,
      <a href=https://myownskyw7.github.io/ target="_blank"> Jiaqi Wang</a><sup>1</sup>,
      <a href=https://scholar.google.com/citations?view_op=list_works&hl=zh-CN&hl=zh-CN&user=AerkT0YAAAAJ&sortby=pubdate target="_blank"> Chen Qian</a><sup>1</sup>,
      <a href=https://scholar.google.com/citations?user=GMzzRRUAAAAJ&hl=zh-CN target="_blank"> Dahua Lin</a><sup>1,2</sup>&#9993,
      <a href=https://liuziwei7.github.io/ target="_blank"> Ziwei Liu</a><sup>5</sup>&#9993 -->
    </p>

<!--     <h1 class="nerf_subheader_v2">
      <sup>1</sup>Shanghai Artificial Intelligence Laboratory, 
      <sup>2</sup>The Chinese University of Hong Kong,
      <sup>3</sup>SenseTime Research, <br>
      <sup>4</sup>Hong Kong University of Science and Technology,
      <sup>5</sup>S-Lab, Nanyang Technological University
      <!-- <sup>6</sup>Centre of Perceptual and Interactive Intelligence -->
<!--     </h1> -->
    <!-- <div class="nerf_equal_v2"><span class="text-span_nerf">*</span><span class="text-span_nerf_star">+</span>Corresponding Author</div> -->

    <!-- </br></br> -->
<!--     <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://arxiv.org/abs/2301.07525" target="_blank">Paper</a>
        <a class="btn btn-primary" href="https://github.com/omniobject3d/OmniObject3D/tree/main" target="_blank">Code</a>
        <a class="btn btn-primary" href="https://opendatalab.com/OpenXD-OmniObject3D-New/download" target="_blank">Dataset</a>
    </div> -->
</div>

    
<div class="container">

<!--<hr>-->
    </br></br>
    <div data-anchor="slide1" class="section nerf_section">
        <div class="grey_container w-container">
            <h2 class="grey-heading_nerf">
                <b>Abstract</b>
            </h2>
            <p class="paragraph-3 nerf_text">
                We propose UniG3D, a unified 3D object generation dataset constructed by employing a universal data transformation pipeline on Objaverse and ShapeNet datasets. This pipeline converts each raw 3D model into comprehensive multi-modal data representation <text, image, point cloud, mesh> by employing rendering engines and multi-modal models. These modules ensure the richness of textual information and the comprehensiveness of data representation.
            </p>   
            <img src="imgs/fig2.png" style="width:75%; margin-right:0px; margin-top:0px;">
            <p class="paragraph-3 nerf_text">
                <br>
                UniG3D offers three contributions: 
                <br>
                <b>1) Comprehensive Multi-Modal Data:</b> We construct a large-scale unified 3D object generation dataset with rich textural information.
                <br>
                <b>2) Universal Data Transformation Pipeline:</b> We propose a universal data transformation pipeline that can convert any 3D data into representations suitable for most 3D object generation methods.
                <br>
                <b>3) Valuable insights:</b> To validate the efficacy of our dataset, we conduct experiments under various input conditions and target 3D representations. Based on our empirical investigations, we present several valuable insights into the impact of various conditions, the efficacy of data expansion, and the significance of text quality.
                <br>
            </p>
        </div>
    </div>

    </br></br>
    <div class="section">
        <s2> Statistics </s2>
            <!-- <h2 class="grey-heading_nerf">
                <b>OmniObject3D Dataset</b>
            </h2> -->
            <hr>
            <!-- <p class="paragraph-3 nerf_text">
                
                OO3D is good
            </p> -->
            
            <div class="columns-5 w-row">
                <style type="text/css">
                    .tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
                    .tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
                      font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:3px 3px;word-break:normal;}
                    .tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
                      font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
                    .tg .tg-baqh{text-align:center;vertical-align:top}
                    .tg .tg-6qw1{background-color:#c0c0c0;text-align:center;vertical-align:top}
                    .tg .tg-6qw2{background-color:#e4e1e1;text-align:center;vertical-align:top}
                    </style>
                    <table class="tg" style="undefined;table-layout: fixed; width: 582px; margin-left:auto;margin-right:auto;">
                    <colgroup>
                    <col style="width: 90px">
                    <col style="width: 70px">
                    <col style="width: 70px">
                    <col style="width: 70px">
                    <col style="width: 70px">
                    </colgroup>
                    <thead>
                      <tr>
                        <th class="tg-6qw1">Dataset</th>
                        <th class="tg-6qw1">#Mesh</th>
                        <th class="tg-6qw1">#PCL</th>
                        <th class="tg-6qw1">#Image</th>
                        <th class="tg-6qw1">#Text</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td class="tg-baqh">UniG3D-<a href=https://shapenet.org/ target="_blank">ShapeNet</a></td>
                        <td class="tg-baqh">500K</td>
                        <td class="tg-baqh">50K</td>
                        <td class="tg-baqh">1 million</td>
                        <td class="tg-baqh">50K</td>
                      </tr>
                      <tr>
                        <td class="tg-baqh">UniG3D-<a href=https://objaverse.allenai.org/ target="_blank">Objaverse</a></td>
                        <td class="tg-baqh">5 million</td>
                        <td class="tg-baqh">500K</td>
                        <td class="tg-baqh">10 million</td>
                        <td class="tg-baqh">500K</td>
                      </tr>
                    </tbody>
                    </table>
            </div>
          
          </br>
            
          <p class="paragraph-3 nerf_text", style="text-align:center">
              Table 1. The statistical information of the four representations in two UniG3D datasets.
          </p>
          
        </br>
            
          <div class="columns-5 w-row">
                <img src="imgs/dataset.png" style="width:50%; margin-right:0px; margin-top:10px;margin-bottom:0px;">
          </div>

        </br>

          <p class="paragraph-3 nerf_text", style="text-align:center">
            Figure 1. A histogram of fine-grained UniG3D categories with representative members from several bins highlighted..
          </p>
    </div>

    <div class="section">
        <s2>Dataset Release</s2>
        <hr>
        
        <div class="columns-5 w-row">
                <img src="imgs/word_cloud.png" style="width:75%; margin-right:0px; margin-top:10px;margin-bottom:0px;">
        </div>

        </br>

        <p class="paragraph-3 nerf_text", style="text-align:center">
            Figure 2. (a) Word cloud of text information. (b) Examples of multi-modal data representation in UniG3D.
        </p>
        
        <br>
        
        <p class="paragraph-3 nerf_text">
            Due to the large storage space required by the entire dataset, we have not found a suitable way to release the quadruples other than text to the public. Therefore, we provide a detailed data transformation pipeline. Based on this pipeline, users can easily obtain data consistent with our dataset. Please refer to the script at <a href=https://github.com/unig3d/unig3d.github.io/blob/master/scripts/readme.md target="_blank">readme.md</a> for details.
        </p>

        <br><br><br><br><br><br>

        <s2> Experimental Methods </s2>
        <hr>
        <div class="columns-5 w-row">
              <img src="imgs/diffusion_process.png" style="width:65%; margin-right:0px; margin-top:10px;margin-bottom:0px;">
        </div>

        </br>

        <p class="paragraph-3 nerf_text", style="text-align:center">
            Figure 3. The directed graphical model depicts the generation process for 3D representations.
        </p>

         <p class="paragraph-3 nerf_text">
                <br>
                Implementation of two widely recognized methods for 3D object generation, tailored to the prevalent 3D representations of point clouds and signed distance functions:
                <br>
                <b>1) Point-E method for point cloud generation:</b> Due to the lack of training code provided in the <a href=https://github.com/openai/point-e target="_blank">official codebase</a>, we develop and release our training code at: <a href=https://github.com/Sense-GVT/unig3d_point-e target="_blank">unig3d_point-e</a>. 
                <br>
                <b>2) SDFusion method for signed distance function generation:</b> We conduct our experiments by utilizing the <a href=https://github.com/yccyenchicheng/SDFusion target="_blank">official codebase</a>.
                <br>
            </p>
    </div>
    <hr>

</div>





<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

<script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
<script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd6c33218.js" type="text/javascript"></script>

<!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->

</body>
</html>
